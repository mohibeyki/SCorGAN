{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KeLzKnmbR_8l"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "wrk = './''\n",
    "df = pd.read_csv('data/uci-epileptic/data.csv')\n",
    "fake_df_normalized = pd.DataFrame(np.load('synthetic.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7WewuuBXYPmZ"
   },
   "outputs": [],
   "source": [
    "fake_df = ((fake_df_normalized.drop(178, 1) * 4000) - 2000).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "id": "8Op0_TqcWC-K",
    "outputId": "a490a968-c414-4a67-c198-e61097681db6"
   },
   "outputs": [],
   "source": [
    "fake_df[\"OUTPUT_LABEL\"] = fake_df_normalized[178] >= 0.5\n",
    "fake_df[\"OUTPUT_LABEL\"] = fake_df[\"OUTPUT_LABEL\"].astype(int)\n",
    "fake_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "id": "QXDp-Mt6SN8k",
    "outputId": "9b2adb41-ca12-4595-81ee-ec7f9408c2fd"
   },
   "outputs": [],
   "source": [
    "df[\"OUTPUT_LABEL\"] = df.y == 1\n",
    "df[\"OUTPUT_LABEL\"] = df[\"OUTPUT_LABEL\"].astype(int)\n",
    "df.pop('y')\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SyETkulbSVvb",
    "outputId": "060a2a98-5f90-4580-81fa-f7888cc470d9"
   },
   "outputs": [],
   "source": [
    "def calc_prevalence(y_actual):\n",
    "    # this function calculates the prevalence of the positive class (label = 1)\n",
    "    return sum(y_actual) / len(y_actual)\n",
    "\n",
    "print(\n",
    "    'prevalence of the positive class: {:.4f} and {:.4f}'.format(\n",
    "        calc_prevalence(df[\"OUTPUT_LABEL\"].values),\n",
    "        calc_prevalence(fake_df[\"OUTPUT_LABEL\"].values)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G_ggO8SSSX8Q",
    "outputId": "fd5cf82e-c1e5-4839-caea-25438b37b1ca"
   },
   "outputs": [],
   "source": [
    "print('# of Columns: {}, {}'.format(len(df.columns), len(fake_df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PqV55MTnSZR7"
   },
   "outputs": [],
   "source": [
    "collist = df.columns.tolist()\n",
    "cols_input = collist[0:178]\n",
    "df_data = df[cols_input + [\"OUTPUT_LABEL\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3pOtFiuXSbux",
    "outputId": "ef75b7a9-d150-4350-f46d-4d0d749c1f9a"
   },
   "outputs": [],
   "source": [
    "# check for duplicated columns in cols_input\n",
    "dup_cols = set([x for x in cols_input if cols_input.count(x) > 1])\n",
    "print(dup_cols)\n",
    "assert len(dup_cols) == 0, \"you have duplicated columns in cols_input\"\n",
    "\n",
    "# check for duplicated columns in df_data\n",
    "cols_df_data = list(df_data.columns)\n",
    "dup_cols = set([x for x in cols_df_data if cols_df_data.count(x) > 1])\n",
    "print(dup_cols)\n",
    "assert len(dup_cols) == 0,'you have duplicated columns in df_data'\n",
    "\n",
    "# check the size of df_data makes sense\n",
    "assert (len(cols_input) + 1) == len(\n",
    "    df_data.columns\n",
    "), \"issue with dimensions of df_data or cols_input\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7NkonzqNZgB9"
   },
   "outputs": [],
   "source": [
    "fake_collist = fake_df.columns.tolist()\n",
    "fake_cols_input = fake_collist[0:178]\n",
    "fake_df_data = fake_df[fake_cols_input + [\"OUTPUT_LABEL\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qO1F7h8yZp07",
    "outputId": "4af36aa3-4c68-476a-b692-4551065ca36b"
   },
   "outputs": [],
   "source": [
    "# check for duplicated columns in cols_input\n",
    "fake_dup_cols = set([x for x in fake_cols_input if fake_cols_input.count(x) > 1])\n",
    "print(fake_dup_cols)\n",
    "assert len(fake_dup_cols) == 0, \"you have duplicated columns in cols_input\"\n",
    "\n",
    "# check for duplicated columns in df_data\n",
    "fake_cols_df_data = list(fake_df_data.columns)\n",
    "fake_dup_cols = set([x for x in fake_cols_df_data if fake_cols_df_data.count(x) > 1])\n",
    "print(fake_dup_cols)\n",
    "assert len(fake_dup_cols) == 0,'you have duplicated columns in df_data'\n",
    "\n",
    "# check the size of df_data makes sense\n",
    "assert (len(fake_cols_input) + 1) == len(\n",
    "    fake_df_data.columns\n",
    "), \"issue with dimensions of df_data or cols_input\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WVjkRJhQSfWT"
   },
   "outputs": [],
   "source": [
    "df_data = df_data.sample(n=len(df_data))\n",
    "df_data = df_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bYc4KRyMZssX"
   },
   "outputs": [],
   "source": [
    "fake_df_data = fake_df_data.sample(n=len(fake_df_data))\n",
    "fake_df_data = fake_df_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-XqXE5p5SgpD",
    "outputId": "d7ced19b-c7d6-4cc1-dcf0-01043353b8b6"
   },
   "outputs": [],
   "source": [
    "df_valid_test = df_data.sample(frac=0.3)\n",
    "print(\"Validation/Test Split Size: %.1f\" % (len(df_valid_test) / len(df_data)))\n",
    "\n",
    "df_test = df_valid_test.sample(frac=0.5)\n",
    "df_valid = df_valid_test.drop(df_test.index)\n",
    "\n",
    "df_train_all = df_data.drop(df_valid_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qgyEewNCZ0Fm",
    "outputId": "8f56d20d-cc37-42aa-c559-7c069df72c1a"
   },
   "outputs": [],
   "source": [
    "fake_df_valid_test = fake_df_data.sample(frac=0.3)\n",
    "print(\"Validation/Test Split Size: %.1f\" % (len(fake_df_valid_test) / len(fake_df_data)))\n",
    "\n",
    "fake_df_test = fake_df_valid_test.sample(frac=0.5)\n",
    "fake_df_valid = fake_df_valid_test.drop(fake_df_test.index)\n",
    "\n",
    "fake_df_train_all = fake_df_data.drop(fake_df_valid_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KSLYyYciShiX",
    "outputId": "38d6fdab-40f4-42bc-8017-5b04ba9cbc16"
   },
   "outputs": [],
   "source": [
    "# check the prevalence of each\n",
    "print(\n",
    "    \"Test prevalence(n = %d):%.3f\"\n",
    "    % (len(df_test), calc_prevalence(df_test.OUTPUT_LABEL.values))\n",
    ")\n",
    "print(\n",
    "    \"Valid prevalence(n = %d):%.3f\"\n",
    "    % (len(df_valid), calc_prevalence(df_valid.OUTPUT_LABEL.values))\n",
    ")\n",
    "print(\n",
    "    \"Train all prevalence(n = %d):%.3f\"\n",
    "    % (len(df_train_all), calc_prevalence(df_train_all.OUTPUT_LABEL.values))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nlIsurOrZ8lE",
    "outputId": "f69f17f4-8bf4-4f68-ce9d-cde2b7215a3e"
   },
   "outputs": [],
   "source": [
    "# check the prevalence of each\n",
    "print(\n",
    "    \"Test prevalence(n = %d):%.3f\"\n",
    "    % (len(fake_df_test), calc_prevalence(fake_df_test.OUTPUT_LABEL.values))\n",
    ")\n",
    "print(\n",
    "    \"Valid prevalence(n = %d):%.3f\"\n",
    "    % (len(fake_df_valid), calc_prevalence(fake_df_valid.OUTPUT_LABEL.values))\n",
    ")\n",
    "print(\n",
    "    \"Train all prevalence(n = %d):%.3f\"\n",
    "    % (len(fake_df_train_all), calc_prevalence(fake_df_train_all.OUTPUT_LABEL.values))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CjWx-1LJStzp",
    "outputId": "4da0a67e-2465-4660-9419-16d602206251"
   },
   "outputs": [],
   "source": [
    "print('all samples (n = %d)'%len(df_data))\n",
    "assert len(df_data) == (len(df_test)+len(df_valid)+len(df_train_all)),'math didnt work'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T8KBGJVfaRnX",
    "outputId": "8fd42385-c2ef-437b-b918-f46342a33942"
   },
   "outputs": [],
   "source": [
    "print('all samples (n = %d)'%len(fake_df_data))\n",
    "assert len(fake_df_data) == (len(fake_df_test)+len(fake_df_valid)+len(fake_df_train_all)), 'math didnt work'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TaeQcazzSwZY",
    "outputId": "d4b73713-ed6b-45d1-be79-9606a62ce4f7"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "rows_pos = df_train_all.OUTPUT_LABEL == 1\n",
    "df_train_pos = df_train_all.loc[rows_pos]\n",
    "df_train_neg = df_train_all.loc[~rows_pos]\n",
    "\n",
    "n = np.min([len(df_train_pos), len(df_train_neg)])\n",
    "\n",
    "df_train = pd.concat([df_train_pos.sample(n=n, random_state=69), df_train_neg.sample(n=n, random_state=69)], axis=0, ignore_index=True)\n",
    "\n",
    "df_train = df_train.sample(n=len(df_train), random_state=69).reset_index(drop=True)\n",
    "\n",
    "print('Train balanced prevalence(n = %d):%.3f'%(len(df_train), calc_prevalence(df_train.OUTPUT_LABEL.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gk-j4P9wabt9",
    "outputId": "facefd61-a7c9-4988-8117-412dfd2191f2"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "rows_pos = fake_df_train_all.OUTPUT_LABEL == 1\n",
    "fake_df_train_pos = fake_df_train_all.loc[rows_pos]\n",
    "fake_df_train_neg = fake_df_train_all.loc[~rows_pos]\n",
    "\n",
    "n = np.min([len(fake_df_train_pos), len(fake_df_train_neg)])\n",
    "\n",
    "fake_df_train = pd.concat([fake_df_train_pos.sample(n=n, random_state=69), fake_df_train_neg.sample(n=n, random_state=69)], axis=0, ignore_index=True)\n",
    "\n",
    "fake_df_train = fake_df_train.sample(n=len(fake_df_train), random_state=69).reset_index(drop=True)\n",
    "\n",
    "print('Train balanced prevalence(n = %d):%.3f'%(len(fake_df_train), calc_prevalence(fake_df_train.OUTPUT_LABEL.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eBo-eQ3FSyse"
   },
   "outputs": [],
   "source": [
    "df_train_all.to_csv(wrk + 'data/processed/df_train_all.csv',index=False)\n",
    "df_train.to_csv(wrk + 'data/processed/df_train.csv',index=False)\n",
    "df_valid.to_csv(wrk + 'data/processed/df_valid.csv',index=False)\n",
    "df_test.to_csv(wrk + 'data/processed/df_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MWXbiWyga4I-"
   },
   "outputs": [],
   "source": [
    "fake_df_train_all.to_csv(wrk + 'data/processed/fake_df_train_all.csv',index=False)\n",
    "fake_df_train.to_csv(wrk + 'data/processed/fake_df_train.csv',index=False)\n",
    "fake_df_valid.to_csv(wrk + 'data/processed/fake_df_valid.csv',index=False)\n",
    "fake_df_test.to_csv(wrk + 'data/processed/fake_df_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2sp_u6r4TILd"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(cols_input, open(wrk + 'data/processed/cols_input.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0hoJDrqBTNp-"
   },
   "outputs": [],
   "source": [
    "# a function to fill missing values with mean of the column if needed\n",
    "def fill_my_missing(df, df_mean, col2use):\n",
    "    # This function fills the missing values\n",
    "\n",
    "    # check the columns are present\n",
    "    for c in col2use:\n",
    "        assert c in df.columns, c + ' not in df'\n",
    "        assert c in df_mean.col.values, c+ 'not in df_mean'\n",
    "    \n",
    "    # replace the mean \n",
    "    for c in col2use:\n",
    "        mean_value = df_mean.loc[df_mean.col == c,'mean_val'].values[0]\n",
    "        df[c] = df[c].fillna(mean_value)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "otwInEa9TPKj",
    "outputId": "a619c9e0-e327-4263-9f52-c66adb991a7a"
   },
   "outputs": [],
   "source": [
    "# create the X and y matrices\n",
    "X_train = df_train[cols_input].values\n",
    "X_train_all = df_train_all[cols_input].values\n",
    "X_valid = df_valid[cols_input].values\n",
    "\n",
    "y_train = df_train['OUTPUT_LABEL'].values\n",
    "y_valid = df_valid['OUTPUT_LABEL'].values\n",
    "\n",
    "print('Training All shapes:',X_train_all.shape)\n",
    "print('Training shapes:',X_train.shape, y_train.shape)\n",
    "print('Validation shapes:',X_valid.shape, y_valid.shape)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler  = StandardScaler()\n",
    "scaler.fit(X_train_all)\n",
    "\n",
    "scalerfile = wrk + 'data/processed/scaler.sav'\n",
    "pickle.dump(scaler, open(scalerfile, 'wb'))\n",
    "scaler = pickle.load(open(scalerfile, 'rb'))\n",
    "\n",
    "# transform our data matrices\n",
    "X_train_tf = scaler.transform(X_train)\n",
    "X_valid_tf = scaler.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "huUxnn_6busT",
    "outputId": "3ab679af-9573-48b5-834d-007fca2b2c59"
   },
   "outputs": [],
   "source": [
    "# create the X and y matrices\n",
    "fake_X_train = fake_df_train[fake_cols_input].values\n",
    "fake_X_train_all = fake_df_train_all[fake_cols_input].values\n",
    "fake_X_valid = fake_df_valid[fake_cols_input].values\n",
    "\n",
    "fake_y_train = fake_df_train['OUTPUT_LABEL'].values\n",
    "fake_y_valid = fake_df_valid['OUTPUT_LABEL'].values\n",
    "\n",
    "print('Training All shapes:',fake_X_train_all.shape)\n",
    "print('Training shapes:',fake_X_train.shape, fake_y_train.shape)\n",
    "print('Validation shapes:',fake_X_valid.shape, fake_y_valid.shape)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "fake_scaler  = StandardScaler()\n",
    "fake_scaler.fit(fake_X_train_all)\n",
    "\n",
    "fake_scalerfile = wrk + 'data/processed/fake_scaler.sav'\n",
    "pickle.dump(fake_scaler, open(fake_scalerfile, 'wb'))\n",
    "fake_scaler = pickle.load(open(fake_scalerfile, 'rb'))\n",
    "\n",
    "# transform our data matrices\n",
    "fake_X_train_tf = fake_scaler.transform(fake_X_train)\n",
    "fake_X_valid_tf = fake_scaler.transform(fake_X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XP00xiZGTQT-"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score\n",
    "def calc_specificity(y_actual, y_pred, thresh):\n",
    "    # calculates specificity\n",
    "    return sum((y_pred < thresh) & (y_actual == 0)) /sum(y_actual ==0)\n",
    "\n",
    "def print_report(y_actual, y_pred, thresh):\n",
    "    auc = roc_auc_score(y_actual, y_pred)\n",
    "    accuracy = accuracy_score(y_actual, (y_pred > thresh))\n",
    "    recall = recall_score(y_actual, (y_pred > thresh))\n",
    "    precision = precision_score(y_actual, (y_pred > thresh))\n",
    "    specificity = calc_specificity(y_actual, y_pred, thresh)\n",
    "    print('AUC:%.3f'%auc)\n",
    "    print('accuracy:%.3f'%accuracy)\n",
    "    print('recall:%.3f'%recall)\n",
    "    print('precision:%.3f'%precision)\n",
    "    print('specificity:%.3f'%specificity)\n",
    "    print('prevalence:%.3f'%calc_prevalence(y_actual))\n",
    "    print(' ')\n",
    "    return auc, accuracy, recall, precision, specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t2fgRFkoTSL6"
   },
   "outputs": [],
   "source": [
    "thresh = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wDhGhfCiTTMg"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xw9X0yLNTUgB",
    "outputId": "0314c965-a30b-4dc8-9de9-cfe06747eb2d"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn=KNeighborsClassifier(n_neighbors = 100)\n",
    "knn.fit(X_train_tf, y_train)\n",
    "\n",
    "y_train_preds = knn.predict_proba(X_train_tf)[:,1]\n",
    "y_valid_preds = knn.predict_proba(X_valid_tf)[:,1]\n",
    "\n",
    "print('KNN')\n",
    "print('Training:')\n",
    "knn_train_auc, knn_train_accuracy, knn_train_recall, \\\n",
    "    knn_train_precision, knn_train_specificity = print_report(y_train,y_train_preds, thresh)\n",
    "print('Validation:')\n",
    "knn_valid_auc, knn_valid_accuracy, knn_valid_recall, \\\n",
    "    knn_valid_precision, knn_valid_specificity = print_report(y_valid,y_valid_preds, thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nlSGHg0cTVyh",
    "outputId": "76dc6b0c-e2dd-489e-c6b8-b5bf20370159"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "fake_knn=KNeighborsClassifier(n_neighbors = 100)\n",
    "fake_knn.fit(fake_X_train_tf, fake_y_train)\n",
    "\n",
    "fake_y_train_preds = fake_knn.predict_proba(X_train_tf)[:,1]\n",
    "fake_y_valid_preds = fake_knn.predict_proba(X_valid_tf)[:,1]\n",
    "\n",
    "print('KNN')\n",
    "print('Training:')\n",
    "fake_knn_train_auc, fake_knn_train_accuracy, fake_knn_train_recall, \\\n",
    "    fake_knn_train_precision, fake_knn_train_specificity = print_report(y_train, fake_y_train_preds, thresh)\n",
    "print('Validation:')\n",
    "fake_knn_valid_auc, fake_knn_valid_accuracy, fake_knn_valid_recall, \\\n",
    "    fake_knn_valid_precision, fake_knn_valid_specificity = print_report(y_valid, fake_y_valid_preds, thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HNutFOmLccKz",
    "outputId": "1d87cf84-ce6b-4792-bb95-54f3dc196845"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(max_depth = 6, random_state = 69)\n",
    "rf.fit(X_train_tf, y_train)\n",
    "\n",
    "y_train_preds = rf.predict_proba(X_train_tf)[:,1]\n",
    "y_valid_preds = rf.predict_proba(X_valid_tf)[:,1]\n",
    "\n",
    "print('Random Forest')\n",
    "print('Training:')\n",
    "rf_train_auc, rf_train_accuracy, rf_train_recall, rf_train_precision, \\\n",
    "rf_train_specificity =print_report(y_train,y_train_preds, thresh)\n",
    "print('Validation:')\n",
    "rf_valid_auc, rf_valid_accuracy, rf_valid_recall, rf_valid_precision, \\\n",
    "rf_valid_specificity = print_report(y_valid,y_valid_preds, thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rmiJIJQPZBUV",
    "outputId": "7f10521c-d596-43d8-9cdf-fbfeb0788a2f"
   },
   "outputs": [],
   "source": [
    "fake_rf = RandomForestClassifier(max_depth = 6, random_state = 69)\n",
    "fake_rf.fit(fake_X_train_tf, fake_y_train)\n",
    "\n",
    "fake_y_train_preds = fake_rf.predict_proba(X_train_tf)[:,1]\n",
    "fake_y_valid_preds = fake_rf.predict_proba(X_valid_tf)[:,1]\n",
    "\n",
    "print('Random Forest')\n",
    "print('Training:')\n",
    "fake_rf_train_auc, fake_rf_train_accuracy, fake_rf_train_recall, fake_rf_train_precision, \\\n",
    "fake_rf_train_specificity = print_report(y_train, fake_y_train_preds, thresh)\n",
    "print('Validation:')\n",
    "fake_rf_valid_auc, fake_rf_valid_accuracy, fake_rf_valid_recall, fake_rf_valid_precision, \\\n",
    "fake_rf_valid_specificity = print_report(y_valid, fake_y_valid_preds, thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6clAcsh5ZD0k",
    "outputId": "fad69c08-be5a-4717-eaf2-70a36ac40ad2"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(random_state = 69)\n",
    "lr.fit(X_train_tf, y_train)\n",
    "\n",
    "y_train_preds = lr.predict_proba(X_train_tf)[:,1]\n",
    "y_valid_preds = lr.predict_proba(X_valid_tf)[:,1]\n",
    "\n",
    "print('Logistic Regression')\n",
    "print('Training:')\n",
    "_ = print_report(y_train,y_train_preds, thresh)\n",
    "print('Validation:')\n",
    "_ = print_report(y_valid,y_valid_preds, thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mkUtZBoNZ1rw",
    "outputId": "1d4028b9-f892-4f8a-a76f-7ca676963be2"
   },
   "outputs": [],
   "source": [
    "fake_lr = LogisticRegression(random_state = 69)\n",
    "fake_lr.fit(fake_X_train_tf, fake_y_train)\n",
    "\n",
    "fake_y_train_preds = fake_lr.predict_proba(X_train_tf)[:,1]\n",
    "fake_y_valid_preds = fake_lr.predict_proba(X_valid_tf)[:,1]\n",
    "\n",
    "print('Logistic Regression')\n",
    "print('Training:')\n",
    "_ = print_report(y_train, fake_y_train_preds, thresh)\n",
    "print('Validation:')\n",
    "_ = print_report(y_valid, fake_y_valid_preds, thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v7CkJi6YZ3eT",
    "outputId": "07fe7ff0-112f-4ada-f6e5-bc1265291e80"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(max_depth = 10, random_state = 69)\n",
    "tree.fit(X_train_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PCUIEYI9aReP",
    "outputId": "a8510708-f501-46f2-d7b5-150b28cac713"
   },
   "outputs": [],
   "source": [
    "y_train_preds = tree.predict_proba(X_train_tf)[:,1]\n",
    "y_valid_preds = tree.predict_proba(X_valid_tf)[:,1]\n",
    "\n",
    "print('Decision Tree')\n",
    "print('Training:')\n",
    "_ = print_report(y_train,y_train_preds, thresh)\n",
    "print('Validation:')\n",
    "_ = print_report(y_valid,y_valid_preds, thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VG1Ubg_AaSsE",
    "outputId": "7f151952-9c5e-4715-9f62-8b575a615744"
   },
   "outputs": [],
   "source": [
    "fake_tree = DecisionTreeClassifier(max_depth = 10, random_state = 69)\n",
    "fake_tree.fit(fake_X_train_tf, fake_y_train)\n",
    "\n",
    "fake_y_train_preds = fake_tree.predict_proba(X_train_tf)[:,1]\n",
    "fake_y_valid_preds = fake_tree.predict_proba(X_valid_tf)[:,1]\n",
    "\n",
    "print('Decision Tree')\n",
    "print('Training:')\n",
    "_ = print_report(y_train, fake_y_train_preds, thresh)\n",
    "print('Validation:')\n",
    "_ = print_report(y_valid, fake_y_valid_preds, thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6FBvqT1nad9-",
    "outputId": "fb062443-d53a-45e9-e901-cfbe5060d4e3"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier(\n",
    "    n_estimators=100, learning_rate=1.0, max_depth=3, random_state=69)\n",
    "gbc.fit(X_train_tf, y_train)\n",
    "\n",
    "y_train_preds = gbc.predict_proba(X_train_tf)[:,1]\n",
    "y_valid_preds = gbc.predict_proba(X_valid_tf)[:,1]\n",
    "\n",
    "print('Gradient Boosting Classifier')\n",
    "print('Training:')\n",
    "_ = print_report(y_train,y_train_preds, thresh)\n",
    "print('Validation:')\n",
    "_ = print_report(y_valid,y_valid_preds, thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bDOGHCCWavwp",
    "outputId": "0274ef17-f65f-4897-a0f1-1f5a9403721d"
   },
   "outputs": [],
   "source": [
    "fake_gbc = GradientBoostingClassifier(\n",
    "    n_estimators=100, learning_rate=1.0, max_depth=3, random_state=69)\n",
    "fake_gbc.fit(fake_X_train_tf, fake_y_train)\n",
    "\n",
    "fake_y_train_preds = fake_gbc.predict_proba(X_train_tf)[:,1]\n",
    "fake_y_valid_preds = fake_gbc.predict_proba(X_valid_tf)[:,1]\n",
    "\n",
    "print('Gradient Boosting Classifier')\n",
    "print('Training:')\n",
    "_ = print_report(y_train, fake_y_train_preds, thresh)\n",
    "print('Validation:')\n",
    "_ = print_report(y_valid, fake_y_valid_preds, thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CNt0k1Q0aw6H",
    "outputId": "c5858c4d-2fee-4d55-f1d3-1dc3a3f33e33"
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "xgbc = XGBClassifier()\n",
    "xgbc.fit(X_train_tf, y_train)\n",
    "\n",
    "y_train_preds = xgbc.predict_proba(X_train_tf)[:,1]\n",
    "y_valid_preds = xgbc.predict_proba(X_valid_tf)[:,1]\n",
    "\n",
    "print('Xtreme Gradient Boosting Classifier')\n",
    "print('Training:')\n",
    "_ = print_report(y_train,y_train_preds, thresh)\n",
    "print('Validation:')\n",
    "_ = print_report(y_valid,y_valid_preds, thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wYGotpxubT3x",
    "outputId": "385d7ee0-8954-4637-b23c-fbfa1582e167"
   },
   "outputs": [],
   "source": [
    "fake_xgbc = XGBClassifier()\n",
    "fake_xgbc.fit(fake_X_train_tf, fake_y_train)\n",
    "\n",
    "fake_y_train_preds = fake_xgbc.predict_proba(X_train_tf)[:,1]\n",
    "fake_y_valid_preds = fake_xgbc.predict_proba(X_valid_tf)[:,1]\n",
    "\n",
    "print('Xtreme Gradient Boosting Classifier')\n",
    "print('Training:')\n",
    "_ = print_report(y_train, fake_y_train_preds, thresh)\n",
    "print('Validation:')\n",
    "_ = print_report(y_valid, fake_y_valid_preds, thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2CI-1NcnbVWc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "UCI-Classifier-SCorGAN.ETD.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
