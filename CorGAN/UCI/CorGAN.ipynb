{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KZKq_k35W6_a"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import copy\n",
    "import gc\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from matplotlib.pyplot import figure\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "or158iZXcTtF",
    "outputId": "8a90efe3-d8e9-41f1-ae1b-4bec6c71e399",
    "tags": []
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "experimentName = 'CorGAN.UCI'\n",
    "\n",
    "parser.add_argument(\"--dataset-path\", type=str, default=os.path.expanduser('~/workspace/data/uci-epileptic/processed.npy'), help=\"Dataset file\")\n",
    "\n",
    "parser.add_argument(\"--n-epochs\", type=int, default=100, help=\"number of epochs of training\")\n",
    "parser.add_argument(\"--n-epochs-ae\", type=int, default=100, help=\"number of epochs of autoencoder training\")\n",
    "parser.add_argument(\"--batch-size\", type=int, default=64, help=\"size of the batches\")\n",
    "parser.add_argument(\"--lr\", type=float, default=0.001, help=\"adam: learning rate\")\n",
    "parser.add_argument(\"--n-cpu\", type=int, default=32, help=\"number of cpu threads to use during batch generation\")\n",
    "parser.add_argument('--n-critic', type=int, default=5, help='number of Discriminator iterations per each Generator iteration')\n",
    "parser.add_argument('--clamp', type=float, default=0.01, help='weight clipping value')\n",
    "parser.add_argument(\"--cuda\", type=bool, default=True, help=\"CUDA activation\")\n",
    "parser.add_argument(\"--latent-dim\", type=int, default=128, help=\"dimensionality of the latent space\")\n",
    "\n",
    "parser.add_argument(\"--pretrained\", type=bool, default=False, help=\"Use pretrained model\")\n",
    "parser.add_argument(\"--pretrained-ae\", type=bool, default=False, help=\"Use pretrained model for autoencoder\")\n",
    "\n",
    "parser.add_argument(\"--expPATH\", type=str, default=os.path.expanduser('~/workspace/pytorch-exports/models/{}'.format(experimentName)), help=\"Export Path\")\n",
    "\n",
    "opt = parser.parse_args([])\n",
    "print(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3syZZGE3ixcZ",
    "outputId": "c3ced1f6-8c91-4b2b-cc1e-25c76d0d0a8e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "######################\n",
    "### Initialization ###\n",
    "######################\n",
    "\n",
    "# Create experiments DIR\n",
    "if not os.path.exists(opt.expPATH):\n",
    "    os.system('mkdir -p {0}'.format(opt.expPATH))\n",
    "\n",
    "# opt.seed = 1024 # fix seed\n",
    "opt.seed = random.randint(1, 10000)\n",
    "\n",
    "print('Random Seed: {}'.format(opt.seed))\n",
    "random.seed(opt.seed)\n",
    "torch.manual_seed(opt.seed)\n",
    "np.random.seed(opt.seed)\n",
    "cudnn.benchmark = True\n",
    "\n",
    "if torch.cuda.is_available() and not opt.cuda:\n",
    "    print(\"WARNING: You have a CUDA device BUT it is not in use...\")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if opt.cuda else \"cpu\")\n",
    "print('using \"{}\" as the tensor processor'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PYJtIeTEil-P"
   },
   "outputs": [],
   "source": [
    "#################################\n",
    "### Reading Dataset from File ###\n",
    "#################################\n",
    "\n",
    "input_data = np.load(opt.dataset_path)\n",
    "\n",
    "sample_size = input_data.shape[0]\n",
    "feature_size = input_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OP96S8Kbcs0y"
   },
   "outputs": [],
   "source": [
    "#####################\n",
    "### Dataset Model ###\n",
    "#####################\n",
    "\n",
    "class EPIDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.sample_size = dataset.shape[0]\n",
    "        self.feature_size = dataset.shape[1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IXkAxe6HS-KJ",
    "outputId": "eb7ddec6-1bd1-4125-aca4-f91f24e81617",
    "tags": []
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "### Dataset Processing ###\n",
    "##########################\n",
    "\n",
    "train_data = input_data[:int(0.8 * sample_size)]\n",
    "test_data = input_data[int(0.8 * sample_size):]\n",
    "print('total samples: {}, features: {}'.format(sample_size, feature_size))\n",
    "print('training data shape: {}, testing data shape: {}, dataset type: {}'.format(train_data.shape, test_data.shape, input_data.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CvS8xM1k8Teu"
   },
   "outputs": [],
   "source": [
    "training_dataloader = DataLoader(\n",
    "    EPIDataset(dataset=train_data),\n",
    "    batch_size=opt.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=opt.n_cpu\n",
    ")\n",
    "\n",
    "testing_dataloader = DataLoader(\n",
    "    EPIDataset(dataset=test_data),\n",
    "    batch_size=opt.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=opt.n_cpu\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ch3VtsBwn5p9"
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "### AutoEncoder Model ###\n",
    "#########################\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        n_channels_base = 4\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1, out_channels=n_channels_base, kernel_size=5, stride=2, padding=0, dilation=1,\n",
    "                      groups=1, bias=True, padding_mode='zeros'),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(in_channels=n_channels_base, out_channels=2 * n_channels_base, kernel_size=5, stride=2, padding=0,\n",
    "                      dilation=1,\n",
    "                      groups=1, bias=True, padding_mode='zeros'),\n",
    "            nn.BatchNorm1d(2 * n_channels_base),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(in_channels=2 * n_channels_base, out_channels=4 * n_channels_base, kernel_size=5, stride=3,\n",
    "                      padding=0, dilation=1,\n",
    "                      groups=1, bias=True, padding_mode='zeros'),\n",
    "            nn.BatchNorm1d(4 * n_channels_base),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(in_channels=4 * n_channels_base, out_channels=8 * n_channels_base, kernel_size=5, stride=3,\n",
    "                      padding=0, dilation=1,\n",
    "                      groups=1, bias=True, padding_mode='zeros'),\n",
    "            nn.BatchNorm1d(8 * n_channels_base),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(in_channels=8 * n_channels_base, out_channels=16 * n_channels_base, kernel_size=3, stride=1,\n",
    "                      padding=0, dilation=1,\n",
    "                      groups=1, bias=True, padding_mode='zeros'),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose1d(in_channels=16 * n_channels_base, out_channels=8 * n_channels_base, kernel_size=5,\n",
    "                               stride=1, padding=0, dilation=1,\n",
    "                               groups=1, bias=True, padding_mode='zeros'),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(in_channels=8 * n_channels_base, out_channels=4 * n_channels_base, kernel_size=5,\n",
    "                               stride=4, padding=0,\n",
    "                               dilation=1,\n",
    "                               groups=1, bias=True, padding_mode='zeros'),\n",
    "            nn.BatchNorm1d(4 * n_channels_base),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(in_channels=4 * n_channels_base, out_channels=2 * n_channels_base, kernel_size=7,\n",
    "                               stride=4,\n",
    "                               padding=0, dilation=1,\n",
    "                               groups=1, bias=True, padding_mode='zeros'),\n",
    "            nn.BatchNorm1d(2 * n_channels_base),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(in_channels=2 * n_channels_base, out_channels=1, kernel_size=7, stride=2,\n",
    "                               padding=0, dilation=1,\n",
    "                               groups=1, bias=True, padding_mode='zeros'),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        return self.encoder(x.view(x.shape[0], 1, x.shape[1]))\n",
    "\n",
    "    def decode(self, x):\n",
    "        return torch.squeeze(self.decoder(x.view(x.shape[0], x.shape[1], 1)), dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decode(self.encode(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bgp1ytGXFDwS"
   },
   "outputs": [],
   "source": [
    "############################\n",
    "### Model Initialization ###\n",
    "############################\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "autoencoder = Autoencoder().cuda() if opt.cuda else Autoencoder()\n",
    "optimizer_A = torch.optim.Adam(autoencoder.parameters(), lr=opt.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jWlJt7_892vs",
    "outputId": "ad0c1c5c-c17c-4a0c-9d5b-253a61d14a97",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#####################################\n",
    "###### AutoEncoder Training #########\n",
    "#####################################\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "if not opt.pretrained_ae:\n",
    "    for epoch in range(opt.n_epochs_ae):\n",
    "        train_loss = 0\n",
    "        autoencoder.train()\n",
    "        for batch in training_dataloader:\n",
    "            batch = batch.to(device)\n",
    "            gen_batch = autoencoder(batch)\n",
    "            loss_A = criterion(gen_batch, batch)\n",
    "            optimizer_A.zero_grad()\n",
    "            loss_A.backward()\n",
    "            optimizer_A.step()\n",
    "            train_loss += loss_A\n",
    "\n",
    "        print(\"[Epoch {:3d}/{:3d}] [Training Loss: {:10.2f}]\".format(epoch + 1, opt.n_epochs_ae, train_loss), flush=True)\n",
    "    torch.save(autoencoder.state_dict(), opt.expPATH + '/autoencoder.model')\n",
    "else:\n",
    "    autoencoder.load_state_dict(torch.load(opt.expPATH + '/autoencoder.model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s7xHg4CmL6BW",
    "outputId": "20a9517c-f364-4f59-c429-49cee3b592f4"
   },
   "outputs": [],
   "source": [
    "errors = 0\n",
    "for batch in testing_dataloader:\n",
    "    batch = batch.to(device)\n",
    "    gen_batch = autoencoder(batch)\n",
    "    diff = torch.abs(gen_batch - batch).view(-1).detach().cpu().numpy()\n",
    "    wrong_digits = diff[diff > 0.05]\n",
    "    errors += len(wrong_digits)\n",
    "print(\"total number of wrong digits: {}\".format(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I0I5dbr5cGlQ"
   },
   "outputs": [],
   "source": [
    "#############################\n",
    "### Generator Model ###\n",
    "#############################\n",
    "\n",
    "# Output should be 64 * 1\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        ngf = 4\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose1d(opt.latent_dim, ngf * 16, 4, 1, 0),\n",
    "            nn.BatchNorm1d(ngf * 16, eps=0.0001, momentum=0.01),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(ngf * 16, ngf * 8, 4, 2, 1),\n",
    "            nn.BatchNorm1d(ngf * 8, eps=0.0001, momentum=0.01),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(ngf * 8, ngf * 4, 4, 2, 1),\n",
    "            nn.BatchNorm1d(ngf * 4, eps=0.0001, momentum=0.01),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(ngf * 4, ngf * 2, 4, 2, 1),\n",
    "            nn.BatchNorm1d(ngf * 2, eps=0.0001, momentum=0.01),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # nn.ConvTranspose1d(ngf * 2, ngf, 4, 2, 1),\n",
    "            # nn.BatchNorm1d(ngf, eps=0.001, momentum=0.01),\n",
    "            # nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(ngf * 2, 1, 4, 2, 1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, x.shape[1], 1)\n",
    "        out = self.main(x)\n",
    "        return torch.squeeze(out, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d5oIATq7r9ek"
   },
   "outputs": [],
   "source": [
    "###########################\n",
    "### Discriminator Model ###\n",
    "###########################\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        ndf = 16\n",
    "        self.conv1 = nn.Sequential(\n",
    "            # input is (nc) x 64 x 64\n",
    "            nn.Conv1d(1, ndf, 8, 4, 1),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            # state size. (ndf) x 32 x 32\n",
    "            nn.Conv1d(ndf, ndf * 2, 8, 4, 1),\n",
    "            nn.BatchNorm1d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv1d(ndf * 2, ndf * 4, 8, 4, 1),\n",
    "            nn.BatchNorm1d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "\n",
    "        # self.conv4 = nn.Sequential(\n",
    "        #     # state size. (ndf*4) x 8 x 8\n",
    "        #     nn.Conv1d(ndf * 4, ndf * 8, 8, 4, 1),\n",
    "        #     nn.BatchNorm1d(ndf * 8),\n",
    "        #     nn.LeakyReLU(0.2, inplace=True),\n",
    "        # )\n",
    "\n",
    "        self.conv4 = nn.Sequential(\n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "            nn.Conv1d(ndf * 4, 1, 2, 1, 0),\n",
    "            # nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        out = self.conv1(input.view(-1, 1, input.shape[1]))\n",
    "        out = self.conv2(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.conv4(out)\n",
    "        return torch.squeeze(out, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7inVoiMu9QS_",
    "tags": []
   },
   "outputs": [],
   "source": [
    "############################\n",
    "### Model Initialization ###\n",
    "############################\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "generator = Generator().cuda() if opt.cuda else Generator()\n",
    "discriminator = Discriminator().cuda() if opt.cuda else Discriminator()\n",
    "\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=opt.lr)\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e83EKUAC3Edo",
    "outputId": "9cf1296a-5942-42ea-d689-7b81e973aa94"
   },
   "outputs": [],
   "source": [
    "if not opt.pretrained:\n",
    "    batches_done = 0\n",
    "\n",
    "    discriminator.train()\n",
    "    generator.train()\n",
    "\n",
    "    for epoch in range(opt.n_epochs):\n",
    "        epoch_start = time.time()\n",
    "        for _ in range(opt.n_critic):\n",
    "            for batch in training_dataloader:\n",
    "                # ---------------------\n",
    "                #  Train Discriminator\n",
    "                # ---------------------\n",
    "                batch = batch.to(device)\n",
    "                for dp in discriminator.parameters():\n",
    "                    dp.requires_grad = True\n",
    "\n",
    "                optimizer_D.zero_grad()\n",
    "                z = torch.randn(batch.shape[0], opt.latent_dim, device=device)\n",
    "                fake_batch = autoencoder.decode(generator(z))\n",
    "                loss_D = torch.mean(discriminator(batch), dim=0) - torch.mean(discriminator(fake_batch.detach()), dim=0)\n",
    "                loss_D.backward()\n",
    "\n",
    "                optimizer_D.step()\n",
    "\n",
    "                for dp in discriminator.parameters():\n",
    "                    dp.data.clamp_(-opt.clamp, opt.clamp)\n",
    "\n",
    "                if batches_done % opt.n_critic == 0:\n",
    "                    # -----------------\n",
    "                    #  Train Generator\n",
    "                    # -----------------\n",
    "                    for dp in discriminator.parameters():\n",
    "                        dp.requires_grad = False\n",
    "\n",
    "                    optimizer_G.zero_grad()\n",
    "\n",
    "                    z = torch.randn(batch.shape[0], opt.latent_dim, device=device)\n",
    "                    fake_batch = autoencoder.decode(generator(z))\n",
    "                    loss_G = torch.mean(discriminator(fake_batch), dim=0)\n",
    "                    loss_G.backward()\n",
    "\n",
    "                    optimizer_G.step()\n",
    "\n",
    "                batches_done += 1\n",
    "                if batches_done % (100 * opt.n_critic) == 0:\n",
    "                    print('[Epoch {:3d}/{:3d}] [Batch {:4d}/{:4d}] [D loss: {:.6f}] [G loss: {:.6f}]'.format(epoch + 1, opt.n_epochs, batches_done % (opt.n_critic * len(training_dataloader)), opt.n_critic * len(training_dataloader), loss_D.item(), loss_G.item()))\n",
    "\n",
    "        print('[Epoch {:3d}/{:3d}] [Time: {:.2f}] [D loss: {:.6f}] [G loss: {:.6f}]'.format(epoch + 1, opt.n_epochs, time.time() - epoch_start, loss_D.item(), loss_G.item()))\n",
    "\n",
    "    torch.save(generator.state_dict(), opt.expPATH + '/generator.model')\n",
    "    torch.save(discriminator.state_dict(), opt.expPATH + '/discriminator.model')\n",
    "else:\n",
    "    generator.load_state_dict(torch.load(opt.expPATH + '/generator.model'))\n",
    "    discriminator.load_state_dict(torch.load(opt.expPATH + '/discriminator.model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rEcQ_acg1xqu",
    "outputId": "4de84bdd-12fa-4d5e-a811-57db75726c25"
   },
   "outputs": [],
   "source": [
    "autoencoder.eval()\n",
    "generator.eval()\n",
    "discriminator.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XuCmebS-zPp5"
   },
   "outputs": [],
   "source": [
    "num_fake_batches = 80\n",
    "fake_data = torch.zeros((0, feature_size), device='cpu')\n",
    "for _ in range(num_fake_batches):\n",
    "  z = torch.randn(opt.batch_size, 128, device=device)\n",
    "  generated_batch = generator(z)\n",
    "  fake_batch = autoencoder.decode(generator(z))\n",
    "  fake_data = torch.cat((fake_data, fake_batch.to('cpu')), 0)\n",
    "np.save(os.path.join(opt.expPATH, \"synthetic.npy\"), fake_data.detach().cpu().numpy(), allow_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u4Aw1fDwKdqj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DCAE.DC.DC.MA.WGAN-GC.UCI.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
