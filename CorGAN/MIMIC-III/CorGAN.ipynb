{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KZKq_k35W6_a"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import copy\n",
    "import gc\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from matplotlib.pyplot import figure\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "or158iZXcTtF",
    "outputId": "8a167371-071f-41ee-e64c-0562eeba1533",
    "tags": []
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "experimentName = 'CORGAN.MIMIC-III'\n",
    "\n",
    "parser.add_argument(\"--dataset-path\", type=str, default=os.path.expanduser('~/workspace/data/mimic-iii-processed/BINARY.h5'), help=\"Dataset file\")\n",
    "\n",
    "parser.add_argument(\"--n-epochs\", type=int, default=100, help=\"number of epochs of training\")\n",
    "parser.add_argument(\"--n-epochs-ae\", type=int, default=100, help=\"number of epochs of pretraining the autoencoder\")\n",
    "parser.add_argument(\"--batch-size\", type=int, default=128, help=\"size of the batches\")\n",
    "parser.add_argument(\"--lr\", type=float, default=0.001, help=\"adam: learning rate\")\n",
    "parser.add_argument(\"--weight-decay\", type=float, default=0.0001, help=\"l2 regularization\")\n",
    "parser.add_argument(\"--b1\", type=float, default=0.9, help=\"adam: decay of first order momentum of gradient\")\n",
    "parser.add_argument(\"--b2\", type=float, default=0.999, help=\"adam: decay of first order momentum of gradient\")\n",
    "parser.add_argument(\"--n-cpu\", type=int, default=32, help=\"number of cpu threads to use during batch generation\")\n",
    "parser.add_argument('--n-critic', type=int, default=5, help='number of D iters per each G iter')\n",
    "parser.add_argument('--clamp', type=float, default=0.01)\n",
    "\n",
    "parser.add_argument(\"--cuda\", type=bool, default=True, help=\"CUDA activation\")\n",
    "parser.add_argument(\"--multiplegpu\", type=bool, default=True, help=\"number of cpu threads to use during batch generation\")\n",
    "parser.add_argument(\"--num-gpu\", type=int, default=1, help=\"Number of GPUs in case of multiple GPU\")\n",
    "\n",
    "parser.add_argument(\"--latent-dim\", type=int, default=128, help=\"dimensionality of the latent space\")\n",
    "parser.add_argument(\"--sample-interval\", type=int, default=100, help=\"interval between samples\")\n",
    "parser.add_argument(\"--epoch-time-show\", type=bool, default=True, help=\"interval betwen image samples\")\n",
    "parser.add_argument(\"--minibatch-averaging\", type=bool, default=False, help=\"Minibatch averaging\")\n",
    "\n",
    "parser.add_argument(\"--pretrained\", type=bool, default=False, help=\"Use pretrained model\")\n",
    "parser.add_argument(\"--pretrained-ae\", type=bool, default=False, help=\"Use pretrained model for autoencoder\")\n",
    "\n",
    "parser.add_argument(\"--expPATH\", type=str, default=os.path.expanduser('~/workspace/pytorch-exports/models/{}'.format(experimentName)), help=\"Export Path\")\n",
    "\n",
    "opt = parser.parse_args([])\n",
    "print(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3syZZGE3ixcZ",
    "outputId": "e9702a09-198f-44a8-a11c-2c8650a69bf5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "######################\n",
    "### Initialization ###\n",
    "######################\n",
    "\n",
    "# Create experiments DIR\n",
    "if not os.path.exists(opt.expPATH):\n",
    "    os.system('mkdir -p {0}'.format(opt.expPATH))\n",
    "\n",
    "# opt.seed = 1024 # fix seed\n",
    "opt.seed = random.randint(1, 10000)\n",
    "\n",
    "print('Random Seed: {}'.format(opt.seed))\n",
    "random.seed(opt.seed)\n",
    "torch.manual_seed(opt.seed)\n",
    "np.random.seed(opt.seed)\n",
    "cudnn.benchmark = True\n",
    "\n",
    "if torch.cuda.is_available() and not opt.cuda:\n",
    "    print(\"WARNING: You have a CUDA device BUT it is not in use...\")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if opt.cuda else \"cpu\")\n",
    "print('using \\'{}\\' as the tensor processor'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PYJtIeTEil-P"
   },
   "outputs": [],
   "source": [
    "#################################\n",
    "### Reading Dataset from File ###\n",
    "#################################\n",
    "\n",
    "input_data = None\n",
    "with h5py.File(opt.dataset_path, 'r') as hf:\n",
    "    input_data = hf.get('dataset')[()]\n",
    "\n",
    "total_samples = input_data.shape[0]\n",
    "feature_size = input_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OP96S8Kbcs0y"
   },
   "outputs": [],
   "source": [
    "#####################\n",
    "### Dataset Model ###\n",
    "#####################\n",
    "\n",
    "class EHRDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.sample_size = dataset.shape[0]\n",
    "        self.feature_size = dataset.shape[1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IXkAxe6HS-KJ",
    "outputId": "e2313d49-0dea-4e06-bf7b-21de506b2df7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "### Dataset Processing ###\n",
    "##########################\n",
    "\n",
    "train_data = input_data[:int(0.8 * total_samples)]\n",
    "test_data = input_data[int(0.8 * total_samples):]\n",
    "print('total samples: {}, features: {}'.format(total_samples, feature_size))\n",
    "print('training data shape: {}, testing data shape: {}, dataset type: {}'.format(train_data.shape, test_data.shape, input_data.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CvS8xM1k8Teu"
   },
   "outputs": [],
   "source": [
    "training_dataloader = DataLoader(\n",
    "    EHRDataset(dataset=train_data),\n",
    "    batch_size=opt.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=opt.n_cpu\n",
    ")\n",
    "\n",
    "testing_dataloader = DataLoader(\n",
    "    EHRDataset(dataset=test_data),\n",
    "    batch_size=opt.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=opt.n_cpu\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QcvJBicPcyhv"
   },
   "outputs": [],
   "source": [
    "def weightsInit(m):\n",
    "    \"\"\"\n",
    "    Custom weight initialization.\n",
    "    :param m: Input argument to extract layer type\n",
    "    :return: Initialized architecture\n",
    "    \"\"\"\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7jSYLExToytb"
   },
   "outputs": [],
   "source": [
    "########################\n",
    "### AutoEncoder Loss ###\n",
    "########################\n",
    "\n",
    "class AutoEncoderLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoderLoss, self).__init__()\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        epsilon = 1e-12\n",
    "        term = target * torch.log(input + epsilon) + (1. - target) * torch.log(1. - input + epsilon)\n",
    "        return torch.mean(-torch.sum(term, 1), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d3x99QhUfV6j"
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "### AutoEncoder Model ###\n",
    "#########################\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        n_channels_base = 4\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1, out_channels=n_channels_base, kernel_size=5, stride=2, padding=0, dilation=1,\n",
    "                      groups=1, bias=True, padding_mode='zeros'),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(in_channels=n_channels_base, out_channels=2 * n_channels_base, kernel_size=5, stride=2, padding=0,\n",
    "                      dilation=1,\n",
    "                      groups=1, bias=True, padding_mode='zeros'),\n",
    "            nn.BatchNorm1d(2 * n_channels_base),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(in_channels=2 * n_channels_base, out_channels=4 * n_channels_base, kernel_size=5, stride=3,\n",
    "                      padding=0, dilation=1,\n",
    "                      groups=1, bias=True, padding_mode='zeros'),\n",
    "            nn.BatchNorm1d(4 * n_channels_base),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(in_channels=4 * n_channels_base, out_channels=8 * n_channels_base, kernel_size=5, stride=3,\n",
    "                      padding=0, dilation=1,\n",
    "                      groups=1, bias=True, padding_mode='zeros'),\n",
    "            nn.BatchNorm1d(8 * n_channels_base),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(in_channels=8 * n_channels_base, out_channels=16 * n_channels_base, kernel_size=5, stride=3,\n",
    "                      padding=0, dilation=1,\n",
    "                      groups=1, bias=True, padding_mode='zeros'),\n",
    "            nn.BatchNorm1d(16 * n_channels_base),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(in_channels=16 * n_channels_base, out_channels=32 * n_channels_base, kernel_size=8, stride=1,\n",
    "                      padding=0, dilation=1,\n",
    "                      groups=1, bias=True, padding_mode='zeros'),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose1d(in_channels=32 * n_channels_base, out_channels=16 * n_channels_base, kernel_size=5,\n",
    "                               stride=1, padding=0, dilation=1,\n",
    "                               groups=1, bias=True, padding_mode='zeros'),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose1d(in_channels=16 * n_channels_base, out_channels=8 * n_channels_base, kernel_size=5,\n",
    "                               stride=4, padding=0,\n",
    "                               dilation=1,\n",
    "                               groups=1, bias=True, padding_mode='zeros'),\n",
    "            nn.BatchNorm1d(8 * n_channels_base),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose1d(in_channels=8 * n_channels_base, out_channels=4 * n_channels_base, kernel_size=7,\n",
    "                               stride=4,\n",
    "                               padding=0, dilation=1,\n",
    "                               groups=1, bias=True, padding_mode='zeros'),\n",
    "            nn.BatchNorm1d(4 * n_channels_base),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose1d(in_channels=4 * n_channels_base, out_channels=2 * n_channels_base, kernel_size=7,\n",
    "                               stride=3,\n",
    "                               padding=0, dilation=1,\n",
    "                               groups=1, bias=True, padding_mode='zeros'),\n",
    "            nn.BatchNorm1d(2 * n_channels_base),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose1d(in_channels=2 * n_channels_base, out_channels=n_channels_base, kernel_size=7, stride=2,\n",
    "                               padding=0, dilation=1,\n",
    "                               groups=1, bias=True, padding_mode='zeros'),\n",
    "            nn.BatchNorm1d(n_channels_base),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose1d(in_channels=n_channels_base, out_channels=1, kernel_size=3, stride=2,\n",
    "                               padding=0, dilation=1,\n",
    "                               groups=1, bias=True, padding_mode='zeros'),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x.view(-1, 1, x.shape[1]))\n",
    "        x = self.decoder(x)\n",
    "        return torch.squeeze(x)\n",
    "\n",
    "    def decode(self, x):\n",
    "        x = self.decoder(x)\n",
    "        return torch.squeeze(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I0I5dbr5cGlQ"
   },
   "outputs": [],
   "source": [
    "#############################\n",
    "### Generator Model ###\n",
    "#############################\n",
    "\n",
    "# Output should be 64 * 20\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        ngf = 4\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose1d(opt.latent_dim, ngf * 16, 4, 1, 0),\n",
    "            nn.BatchNorm1d(ngf * 16, eps=0.0001, momentum=0.01),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(ngf * 16, ngf * 8, 4, 2, 1),\n",
    "            nn.BatchNorm1d(ngf * 8, eps=0.0001, momentum=0.01),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(ngf * 8, ngf * 4, 4, 2, 1),\n",
    "            nn.BatchNorm1d(ngf * 4, eps=0.0001, momentum=0.01),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(ngf * 4, ngf * 2, 4, 2, 1),\n",
    "            nn.BatchNorm1d(ngf * 2, eps=0.0001, momentum=0.01),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(ngf * 2, ngf, 4, 2, 1),\n",
    "            nn.BatchNorm1d(ngf, eps=0.001, momentum=0.01),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(ngf, 1, 4, 2, 1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, x.shape[1], 1)\n",
    "        out = self.main(x)\n",
    "        return torch.squeeze(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d5oIATq7r9ek"
   },
   "outputs": [],
   "source": [
    "###########################\n",
    "### Discriminator Model ###\n",
    "###########################\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        ndf = 16\n",
    "        self.conv1 = nn.Sequential(\n",
    "            # input is (nc) x 64 x 64\n",
    "            nn.Conv1d(1, ndf, 8, 4, 1),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            # state size. (ndf) x 32 x 32\n",
    "            nn.Conv1d(ndf, ndf * 2, 8, 4, 1),\n",
    "            nn.BatchNorm1d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv1d(ndf * 2, ndf * 4, 8, 4, 1),\n",
    "            nn.BatchNorm1d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "\n",
    "        self.conv4 = nn.Sequential(\n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv1d(ndf * 4, ndf * 8, 8, 4, 1),\n",
    "            nn.BatchNorm1d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "\n",
    "        self.conv5 = nn.Sequential(\n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "            nn.Conv1d(ndf * 8, 1, 3, 1, 0),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        out = self.conv1(input.view(-1, 1, input.shape[1]))\n",
    "        out = self.conv2(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.conv4(out)\n",
    "        out = self.conv5(out)\n",
    "        return torch.squeeze(out, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7inVoiMu9QS_",
    "outputId": "174eebc9-fe7e-49fe-ae4c-52e6614328a9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "############################\n",
    "### Model Initialization ###\n",
    "############################\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "autoencoder = Autoencoder()\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "Tensor = torch.FloatTensor\n",
    "\n",
    "one = torch.FloatTensor([1])\n",
    "mone = one * -1\n",
    "\n",
    "if opt.cuda:\n",
    "    autoencoder.cuda()\n",
    "    generator.cuda()\n",
    "    discriminator.cuda()\n",
    "    one = one.cuda()\n",
    "    mone = mone.cuda()\n",
    "    Tensor = torch.cuda.FloatTensor\n",
    "\n",
    "generator_params = [{'params': generator.parameters()}, {'params': autoencoder.decoder.parameters(), 'lr': 1e-4}]\n",
    "\n",
    "optimizer_A = torch.optim.Adam(autoencoder.parameters(), lr=opt.lr)\n",
    "optimizer_G = torch.optim.Adam(generator_params, lr=opt.lr)\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr)\n",
    "\n",
    "generator.apply(weightsInit)\n",
    "discriminator.apply(weightsInit)\n",
    "autoencoder.apply(weightsInit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jWlJt7_892vs",
    "outputId": "0afa7984-2870-4a78-d108-7c1cccd86846",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#####################################\n",
    "###### AutoEncoder Training #########\n",
    "#####################################\n",
    "\n",
    "criterion = AutoEncoderLoss()\n",
    "\n",
    "if not opt.pretrained_ae:\n",
    "    for epoch in range(opt.n_epochs_ae):\n",
    "        autoencoder.train()\n",
    "        for batch in training_dataloader:\n",
    "            batch = batch.to(device)\n",
    "            generated = autoencoder(batch)\n",
    "            loss_A = criterion(generated, batch)\n",
    "            optimizer_A.zero_grad()\n",
    "            loss_A.backward()\n",
    "            optimizer_A.step()\n",
    "\n",
    "        errors = 0\n",
    "        testing_loss = 0\n",
    "        autoencoder.eval()\n",
    "        for batch in testing_dataloader:\n",
    "            batch = batch.to(device)\n",
    "            generated = autoencoder(batch)\n",
    "            res = generated.round()\n",
    "            diff = torch.abs(res - batch).view(1, 1, -1)[0][0].cpu().detach().numpy()\n",
    "            bad_diffs = diff[diff > 0.5]\n",
    "            errors += len(bad_diffs)\n",
    "            testing_loss += criterion(generated, batch)\n",
    "\n",
    "        print(\"[Epoch {:3d}/{:3d} of autoencoder training] [Loss: {:10.2f}] [errors: {:6d}]\".format(epoch + 1, opt.n_epochs_ae, testing_loss, errors), flush=True)\n",
    "    torch.save(autoencoder.state_dict(), opt.expPATH + '/autoencoder.model')\n",
    "else:\n",
    "    autoencoder.load_state_dict(torch.load(opt.expPATH + '/autoencoder.model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s7xHg4CmL6BW",
    "outputId": "f77dff9a-dbda-4e8a-f82f-268543fdd3f9"
   },
   "outputs": [],
   "source": [
    "errors = 0\n",
    "for batch in testing_dataloader:\n",
    "    batch = batch.to(device)\n",
    "    generated = autoencoder(batch)\n",
    "    res = generated.round()\n",
    "    diff = torch.abs(res - batch).view(1, 1, -1)[0][0].cpu().detach().numpy()\n",
    "    bad_diffs = diff[diff > 0.5]\n",
    "    errors += len(bad_diffs)\n",
    "print(\"total number of bad digits: {}\".format(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e83EKUAC3Edo",
    "outputId": "dcac40a4-e220-476b-d1a2-0fda4ed4fabd"
   },
   "outputs": [],
   "source": [
    "if not opt.pretrained:\n",
    "    batches_done = 0\n",
    "\n",
    "    discriminator.train()\n",
    "    generator.train()\n",
    "\n",
    "    gen_iterations = 0\n",
    "    for epoch in range(opt.n_epochs):\n",
    "        epoch_start = time.time()\n",
    "\n",
    "        for batch in training_dataloader:\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "            batch = batch.to(device)\n",
    "\n",
    "            for dp in discriminator.parameters():\n",
    "                dp.requires_grad = True\n",
    "\n",
    "            if gen_iterations < 25 or gen_iterations % 500 == 0:\n",
    "                n_critic = 100\n",
    "            else:\n",
    "                n_critic = opt.n_critic\n",
    "\n",
    "            for _ in range(opt.n_critic):\n",
    "                for dp in discriminator.parameters():\n",
    "                    dp.data.clamp_(-opt.clamp, opt.clamp)\n",
    "\n",
    "                # reset gradients of discriminator\n",
    "                optimizer_D.zero_grad()\n",
    "\n",
    "                loss_D_real = torch.mean(discriminator(batch), dim=0)\n",
    "                loss_D_real.backward(one)\n",
    "\n",
    "                # Sample noise as generator input\n",
    "                z = torch.randn(batch.shape[0], opt.latent_dim, device=device)\n",
    "                # Generate a batch of images\n",
    "                fake_batch = torch.squeeze(autoencoder.decode(generator(z).unsqueeze(dim=2)))\n",
    "\n",
    "                # Error\n",
    "                loss_D_fake = torch.mean(discriminator(fake_batch.detach()), dim=0)\n",
    "                loss_D_fake.backward(mone)\n",
    "\n",
    "                # Optimizer stepz\n",
    "                optimizer_D.step()\n",
    "\n",
    "            # -----------------\n",
    "            #  Train Generator\n",
    "            # -----------------\n",
    "\n",
    "            for dp in discriminator.parameters():\n",
    "                dp.requires_grad = False\n",
    "\n",
    "            optimizer_G.zero_grad()\n",
    "\n",
    "            # Sample noise as generator input\n",
    "            z = torch.randn(batch.shape[0], opt.latent_dim, device=device)\n",
    "\n",
    "            # Generate a batch of images\n",
    "            fake_batch = torch.squeeze(autoencoder.decode(generator(z).unsqueeze(dim=2)))\n",
    "\n",
    "            # uncomment if there is no autoencoder\n",
    "            loss_G = torch.mean(discriminator(fake_batch), dim=0)\n",
    "            loss_G.backward(one)\n",
    "            optimizer_G.step()\n",
    "            batches_done += 1\n",
    "\n",
    "            if batches_done % 100 == 0:\n",
    "                print('[Epoch {:3d}/{:3d}] [Batch {:3d}/{:3d}] [D loss: {:.5f}] [G loss: {:.5f}]'.format(epoch + 1, opt.n_epochs, batches_done % len(training_dataloader), len(training_dataloader), loss_D_real.item() + loss_D_fake.item(), loss_G.item()))\n",
    "\n",
    "        print('[Epoch {:3d}/{:3d}] [Time: {:.2f}] [D loss: {:.5f}] [G loss: {:.5f}]'.format(epoch + 1, opt.n_epochs, time.time() - epoch_start, loss_D_real.item() + loss_D_fake.item(), loss_G.item()))\n",
    "\n",
    "    torch.save(generator.state_dict(), opt.expPATH + '/generator.model')\n",
    "    torch.save(discriminator.state_dict(), opt.expPATH + '/discriminator.model')\n",
    "else:\n",
    "    generator.load_state_dict(torch.load(opt.expPATH + '/generator.model'))\n",
    "    discriminator.load_state_dict(torch.load(opt.expPATH + '/discriminator.model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rEcQ_acg1xqu",
    "outputId": "0e46fac8-25b3-42f2-b901-fb7068f426cd"
   },
   "outputs": [],
   "source": [
    "autoencoder.eval()\n",
    "generator.eval()\n",
    "discriminator.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XuCmebS-zPp5"
   },
   "outputs": [],
   "source": [
    "num_fake_batches = 80\n",
    "fake_data = torch.zeros((0, feature_size), device='cpu')\n",
    "for _ in range(num_fake_batches):\n",
    "  z = torch.randn(opt.batch_size, 128, device=device)\n",
    "  generated_batch = generator(z)\n",
    "  fake_batch = torch.squeeze(autoencoder.decode(generator(z).unsqueeze(dim=2)))\n",
    "  fake_data = torch.cat((fake_data, fake_batch.round().to('cpu')), 0)\n",
    "np.save(os.path.join(opt.expPATH, \"synthetic.npy\"), fake_data.detach().cpu().numpy(), allow_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uadDPenk74Ok"
   },
   "outputs": [],
   "source": [
    "gen_samples = np.load(os.path.join(opt.expPATH, \"synthetic.npy\"), allow_pickle=False)\n",
    "\n",
    "# load real data\n",
    "real_samples = train_data[0:gen_samples.shape[0], :]\n",
    "\n",
    "# dimenstion wise probability\n",
    "prob_real = np.mean(real_samples, axis=0)\n",
    "prob_syn = np.mean(gen_samples, axis=0)\n",
    "\n",
    "figure(num=None, figsize=(12, 12), dpi=80, facecolor='w', edgecolor='k')\n",
    "p1 = plt.scatter(prob_real, prob_syn, c=\"b\", alpha=0.7, label=experimentName, s=9)\n",
    "x_max = max(np.max(prob_real), np.max(prob_syn))\n",
    "x = np.linspace(0, x_max + 0.05, 1000)\n",
    "p2 = plt.plot(x, x, linestyle='-', color='k', label=\"Ideal\")  # solid\n",
    "plt.tick_params(labelsize=12)\n",
    "plt.legend(loc=2, prop={'size': 13})\n",
    "plt.title('Dimension Wise Probability')\n",
    "plt.xlabel('MIMIC III')\n",
    "plt.ylabel('Synthetic Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CORGAN.ETD.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
