{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KZKq_k35W6_a"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import copy\n",
    "import gc\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import h5py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "or158iZXcTtF",
    "outputId": "e40e2259-432b-4939-bbb9-f0af2f2ffc8d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "experimentName = 'medGAN.MIMIC-III'\n",
    "\n",
    "parser.add_argument(\"--dataset-path\", type=str, default=os.path.expanduser('~/workspace/data/mimic-iii-processed/BINARY.h5'), help=\"Dataset file\")\n",
    "\n",
    "parser.add_argument(\"--n-epochs\", type=int, default=100, help=\"number of epochs of training\")\n",
    "parser.add_argument(\"--n-epochs-ae\", type=int, default=100, help=\"number of epochs of autoencoder training\")\n",
    "parser.add_argument(\"--batch-size\", type=int, default=64, help=\"size of the batches\")\n",
    "parser.add_argument(\"--lr\", type=float, default=0.001, help=\"adam: learning rate\")\n",
    "parser.add_argument(\"--b1\", type=float, default=0.9, help=\"adam: decay of first order momentum of gradient\")\n",
    "parser.add_argument(\"--b2\", type=float, default=0.999, help=\"adam: decay of first order momentum of gradient\")\n",
    "parser.add_argument(\"--n-cpu\", type=int, default=32, help=\"number of cpu threads to use during batch generation\")\n",
    "parser.add_argument('--n-critic', type=int, default=5, help='number of Discriminator iterations per each Generator iteration')\n",
    "parser.add_argument('--clamp', type=float, default=0.01, help='weight clipping value')\n",
    "parser.add_argument(\"--cuda\", type=bool, default=True, help=\"CUDA activation\")\n",
    "parser.add_argument(\"--multiple-gpu\", type=bool, default=True, help=\"number of cpu threads to use during batch generation\")\n",
    "parser.add_argument(\"--num-gpu\", type=int, default=1, help=\"Number of GPUs in case of multiple GPU\")\n",
    "parser.add_argument(\"--latent-dim\", type=int, default=128, help=\"dimensionality of the latent space\")\n",
    "parser.add_argument(\"--weight-decay\", type=float, default=0.0001, help=\"l2 regularization\")\n",
    "\n",
    "parser.add_argument(\"--sample_interval\", type=int, default=100, help=\"interval between samples\")\n",
    "parser.add_argument(\"--epoch-time-show\", type=bool, default=True, help=\"interval betwen image samples\")\n",
    "parser.add_argument(\"--epoch-save-model-freq\", type=int, default=100, help=\"number of epops per model save\")\n",
    "parser.add_argument(\"--minibatch-averaging\", type=bool, default=False, help=\"Minibatch averaging\")\n",
    "\n",
    "parser.add_argument(\"--pretrained\", type=bool, default=False, help=\"Use pretrained model\")\n",
    "parser.add_argument(\"--pretrained-ae\", type=bool, default=False, help=\"Use pretrained model for autoencoder\")\n",
    "\n",
    "parser.add_argument(\"--expPATH\", type=str, default=os.path.expanduser('~/workspace/pytorch-exports/models/{}'.format(experimentName)), help=\"Export Path\")\n",
    "\n",
    "opt = parser.parse_args([])\n",
    "print(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3syZZGE3ixcZ",
    "outputId": "4c0b0231-9012-422f-bcea-9c30374367dd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "######################\n",
    "### Initialization ###\n",
    "######################\n",
    "\n",
    "# Create experiments DIR\n",
    "if not os.path.exists(opt.expPATH):\n",
    "    os.system('mkdir -p {0}'.format(opt.expPATH))\n",
    "\n",
    "# opt.seed = 1024 # fix seed\n",
    "opt.seed = random.randint(1, 10000)\n",
    "\n",
    "print('Random Seed: {}'.format(opt.seed))\n",
    "random.seed(opt.seed)\n",
    "torch.manual_seed(opt.seed)\n",
    "np.random.seed(opt.seed)\n",
    "cudnn.benchmark = True\n",
    "\n",
    "if torch.cuda.is_available() and not opt.cuda:\n",
    "    print(\"WARNING: You have a CUDA device BUT it is not in use...\")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if opt.cuda else \"cpu\")\n",
    "print('using \\'{}\\' as the tensor processor'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PYJtIeTEil-P"
   },
   "outputs": [],
   "source": [
    "#################################\n",
    "### Reading Dataset from File ###\n",
    "#################################\n",
    "\n",
    "input_data = None\n",
    "with h5py.File(opt.dataset_path, 'r') as hf:\n",
    "    input_data = hf.get('dataset')[()]\n",
    "\n",
    "total_samples = input_data.shape[0]\n",
    "feature_size = input_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OP96S8Kbcs0y"
   },
   "outputs": [],
   "source": [
    "#####################\n",
    "### Dataset Model ###\n",
    "#####################\n",
    "\n",
    "class EHRDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.sample_size = dataset.shape[0]\n",
    "        self.feature_size = dataset.shape[1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IXkAxe6HS-KJ",
    "outputId": "640edb0a-a0a7-4c51-e3e3-07d75cba9189",
    "tags": []
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "### Dataset Processing ###\n",
    "##########################\n",
    "\n",
    "train_data = input_data[:int(0.8 * total_samples)]\n",
    "test_data = input_data[int(0.8 * total_samples):]\n",
    "print('total samples: {}, features: {}'.format(total_samples, feature_size))\n",
    "print('training data shape: {}, testing data shape: {}, dataset type: {}'.format(train_data.shape, test_data.shape, input_data.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CvS8xM1k8Teu"
   },
   "outputs": [],
   "source": [
    "training_dataloader = DataLoader(\n",
    "    EHRDataset(dataset=train_data),\n",
    "    batch_size=opt.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=opt.n_cpu\n",
    ")\n",
    "\n",
    "testing_dataloader = DataLoader(\n",
    "    EHRDataset(dataset=test_data),\n",
    "    batch_size=opt.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=opt.n_cpu\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QcvJBicPcyhv"
   },
   "outputs": [],
   "source": [
    "def weightsInit(m):\n",
    "    \"\"\"\n",
    "    Custom weight initialization.\n",
    "    :param m: Input argument to extract layer type\n",
    "    :return: Initialized architecture\n",
    "    \"\"\"\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7jSYLExToytb"
   },
   "outputs": [],
   "source": [
    "########################\n",
    "### AutoEncoder Loss ###\n",
    "########################\n",
    "\n",
    "class AutoEncoderLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoderLoss, self).__init__()\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        epsilon = 1e-12\n",
    "        term = target * torch.log(input + epsilon) + (1. - target) * torch.log(1. - input + epsilon)\n",
    "        return torch.mean(-torch.sum(term, 1), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d3x99QhUfV6j"
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "### AutoEncoder Model ###\n",
    "#########################\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(feature_size, 128),\n",
    "            nn.Tanh())\n",
    "        self.decoder = nn.Sequential(nn.Linear(128, feature_size)\n",
    "                                     , nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "    def decode(self, x):\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I0I5dbr5cGlQ"
   },
   "outputs": [],
   "source": [
    "#############################\n",
    "### Generator Model ###\n",
    "#############################\n",
    "\n",
    "# Output should be 64 * 20\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.genDim = 128\n",
    "        self.linear1 = nn.Linear(opt.latent_dim, self.genDim)\n",
    "        self.bn1 = nn.BatchNorm1d(self.genDim, eps=0.001, momentum=0.01)\n",
    "        self.activation1 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(opt.latent_dim, self.genDim)\n",
    "        self.bn2 = nn.BatchNorm1d(self.genDim, eps=0.001, momentum=0.01)\n",
    "        self.activation2 = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Layer 1\n",
    "        residual = x\n",
    "        temp = self.activation1(self.bn1(self.linear1(x)))\n",
    "        out1 = temp + residual\n",
    "\n",
    "        # Layer 2\n",
    "        residual = out1\n",
    "        temp = self.activation2(self.bn2(self.linear2(out1)))\n",
    "        out2 = temp + residual\n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d5oIATq7r9ek"
   },
   "outputs": [],
   "source": [
    "###########################\n",
    "### Discriminator Model ###\n",
    "###########################\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        # Discriminator's parameters\n",
    "        self.disDim = 256\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(feature_size, self.disDim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.disDim, int(self.disDim / 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(self.disDim / 2), 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Feeding the model\n",
    "        output = self.model(x)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7inVoiMu9QS_",
    "outputId": "da259ccf-62a6-48ae-f4c6-fce56292d967",
    "tags": []
   },
   "outputs": [],
   "source": [
    "############################\n",
    "### Model Initialization ###\n",
    "############################\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "autoencoder = Autoencoder()\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "Tensor = torch.FloatTensor\n",
    "\n",
    "one = torch.FloatTensor([1])\n",
    "mone = one * -1\n",
    "\n",
    "if opt.cuda:\n",
    "    autoencoder.cuda()\n",
    "    generator.cuda()\n",
    "    discriminator.cuda()\n",
    "    one = one.cuda()\n",
    "    mone = mone.cuda()\n",
    "    Tensor = torch.cuda.FloatTensor\n",
    "\n",
    "generator_params = [{'params': generator.parameters()}, {'params': autoencoder.decoder.parameters(), 'lr': 1e-4}]\n",
    "\n",
    "optimizer_A = torch.optim.Adam(autoencoder.parameters(), lr=opt.lr)\n",
    "optimizer_G = torch.optim.Adam(generator_params, lr=opt.lr)\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr)\n",
    "\n",
    "generator.apply(weightsInit)\n",
    "discriminator.apply(weightsInit)\n",
    "autoencoder.apply(weightsInit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jWlJt7_892vs",
    "outputId": "c1a28253-1b37-4bf3-82e8-b83235d56c1b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#####################################\n",
    "###### AutoEncoder Training #########\n",
    "#####################################\n",
    "\n",
    "criterion = AutoEncoderLoss()\n",
    "\n",
    "if not opt.pretrained_ae:\n",
    "    for epoch in range(opt.n_epochs_ae):\n",
    "        autoencoder.train()\n",
    "        for batch in training_dataloader:\n",
    "            batch = Variable(batch.type(Tensor))\n",
    "            generated = autoencoder(batch)\n",
    "            loss_A = criterion(generated, batch)\n",
    "            optimizer_A.zero_grad()\n",
    "            loss_A.backward()\n",
    "            optimizer_A.step()\n",
    "\n",
    "        errors = 0\n",
    "        testing_loss = 0\n",
    "        autoencoder.eval()\n",
    "        for batch in testing_dataloader:\n",
    "            batch = Variable(batch.type(Tensor))\n",
    "            generated = autoencoder(batch)\n",
    "            res = generated.round()\n",
    "            diff = torch.abs(res - batch).view(1, 1, -1)[0][0].cpu().detach().numpy()\n",
    "            bad_diffs = diff[diff > 0.5]\n",
    "            errors += len(bad_diffs)\n",
    "            testing_loss += criterion(generated, batch)\n",
    "\n",
    "        print(\"[Epoch {:3d}/{:3d} of autoencoder training] [Loss: {:10.2f}] [errors: {:6d}]\".format(epoch + 1, opt.n_epochs_ae, testing_loss, errors), flush=True)\n",
    "    torch.save(autoencoder.state_dict(), opt.expPATH + '/autoencoder.model')\n",
    "else:\n",
    "    autoencoder.load_state_dict(torch.load(opt.expPATH + '/autoencoder.model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s7xHg4CmL6BW",
    "outputId": "15ac125b-d0dd-41a8-b053-10de420fe4aa"
   },
   "outputs": [],
   "source": [
    "errors = 0\n",
    "for batch in testing_dataloader:\n",
    "    batch = Variable(batch.type(Tensor))\n",
    "    generated = autoencoder(batch)\n",
    "    res = generated.round()\n",
    "    diff = torch.abs(res - batch).view(1, 1, -1)[0][0].cpu().detach().numpy()\n",
    "    bad_diffs = diff[diff > 0.5]\n",
    "    errors += len(bad_diffs)\n",
    "print(\"total number of bad digits: {}\".format(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e83EKUAC3Edo",
    "outputId": "04bf60db-9b67-43eb-f940-314fa409a395"
   },
   "outputs": [],
   "source": [
    "if not opt.pretrained:\n",
    "    batches_done = 0\n",
    "\n",
    "    discriminator.train()\n",
    "    generator.train()\n",
    "\n",
    "    gen_iterations = 0\n",
    "    for epoch in range(opt.n_epochs):\n",
    "        epoch_start = time.time()\n",
    "\n",
    "        for batch in training_dataloader:\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "            batch = Variable(batch.type(Tensor))\n",
    "\n",
    "            for dp in discriminator.parameters():\n",
    "                dp.requires_grad = True\n",
    "\n",
    "            for _ in range(opt.n_critic):\n",
    "                for dp in discriminator.parameters():\n",
    "                    dp.data.clamp_(-opt.clamp, opt.clamp)\n",
    "\n",
    "                # reset gradients of discriminator\n",
    "                optimizer_D.zero_grad()\n",
    "\n",
    "                loss_D_real = torch.mean(discriminator(batch), dim=0)\n",
    "                loss_D_real.backward(one)\n",
    "\n",
    "                # Sample noise as generator input\n",
    "                z = torch.randn(batch.shape[0], opt.latent_dim, device=device)\n",
    "                # Generate a batch of images\n",
    "                fake_batch = autoencoder.decoder(generator(z))\n",
    "\n",
    "                # Error\n",
    "                loss_D_fake = torch.mean(discriminator(fake_batch.detach()), dim=0)\n",
    "                loss_D_fake.backward(mone)\n",
    "\n",
    "                # Optimizer stepz\n",
    "                optimizer_D.step()\n",
    "\n",
    "            # -----------------\n",
    "            #  Train Generator\n",
    "            # -----------------\n",
    "\n",
    "            for dp in discriminator.parameters():\n",
    "                dp.requires_grad = False\n",
    "\n",
    "            optimizer_G.zero_grad()\n",
    "\n",
    "            # Sample noise as generator input\n",
    "            z = torch.randn(batch.shape[0], opt.latent_dim, device=device)\n",
    "\n",
    "            # Generate a batch of images\n",
    "            fake_batch = autoencoder.decoder(generator(z))\n",
    "\n",
    "            # uncomment if there is no autoencoder\n",
    "            loss_G = torch.mean(discriminator(fake_batch), dim=0)\n",
    "            loss_G.backward(one)\n",
    "            optimizer_G.step()\n",
    "            batches_done += 1\n",
    "\n",
    "            if batches_done % 100 == 0:\n",
    "                print('[Epoch {:3d}/{:3d}] [Batch {:3d}/{:3d}] [D loss: {:.5f}] [G loss: {:.5f}]'.format(epoch + 1, opt.n_epochs, batches_done % len(training_dataloader), len(training_dataloader), loss_D_real.item() + loss_D_fake.item(), loss_G.item()))\n",
    "\n",
    "        print('[Epoch {:3d}/{:3d}] [Time: {:.2f}] [D loss: {:.5f}] [G loss: {:.5f}]'.format(epoch + 1, opt.n_epochs, time.time() - epoch_start, loss_D_real.item() + loss_D_fake.item(), loss_G.item()))\n",
    "\n",
    "    torch.save(generator.state_dict(), opt.expPATH + '/generator.model')\n",
    "    torch.save(discriminator.state_dict(), opt.expPATH + '/discriminator.model')\n",
    "else:\n",
    "    generator.load_state_dict(torch.load(opt.expPATH + '/generator.model'))\n",
    "    discriminator.load_state_dict(torch.load(opt.expPATH + '/discriminator.model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rEcQ_acg1xqu",
    "outputId": "8ebc492e-f2b4-4ecd-9920-4fefc14b3bda"
   },
   "outputs": [],
   "source": [
    "autoencoder.eval()\n",
    "generator.eval()\n",
    "discriminator.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XuCmebS-zPp5"
   },
   "outputs": [],
   "source": [
    "num_fake_batches = 80\n",
    "fake_data = torch.zeros((0, feature_size), device='cpu')\n",
    "for _ in range(num_fake_batches):\n",
    "  z = torch.randn(opt.batch_size, 128, device=device)\n",
    "  generated_batch = generator(z)\n",
    "  fake_batch = autoencoder.decoder(generator(z))\n",
    "  fake_data = torch.cat((fake_data, fake_batch.round().to('cpu')), 0)\n",
    "np.save(os.path.join(opt.expPATH, \"synthetic.npy\"), fake_data.detach().cpu().numpy(), allow_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uadDPenk74Ok"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "medGAN.ETD.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
