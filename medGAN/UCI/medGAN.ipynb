{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KZKq_k35W6_a"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import copy\n",
    "import gc\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from matplotlib.pyplot import figure\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "or158iZXcTtF",
    "outputId": "3fdaff49-afe9-468a-9d57-c206996fa743",
    "tags": []
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "experimentName = 'medGAN.UCI'\n",
    "\n",
    "parser.add_argument(\"--dataset-path\", type=str, default=os.path.expanduser('~/workspace/data/uci-epileptic/processed.npy'), help=\"Dataset file\")\n",
    "\n",
    "parser.add_argument(\"--n-epochs\", type=int, default=100, help=\"number of epochs of training\")\n",
    "parser.add_argument(\"--n-epochs-ae\", type=int, default=100, help=\"number of epochs of autoencoder training\")\n",
    "parser.add_argument(\"--batch-size\", type=int, default=64, help=\"size of the batches\")\n",
    "parser.add_argument(\"--lr\", type=float, default=0.001, help=\"adam: learning rate\")\n",
    "parser.add_argument(\"--n-cpu\", type=int, default=32, help=\"number of cpu threads to use during batch generation\")\n",
    "parser.add_argument('--n-critic', type=int, default=5, help='number of Discriminator iterations per each Generator iteration')\n",
    "parser.add_argument('--clamp', type=float, default=0.01, help='weight clipping value')\n",
    "parser.add_argument(\"--cuda\", type=bool, default=True, help=\"CUDA activation\")\n",
    "parser.add_argument(\"--latent-dim\", type=int, default=128, help=\"dimensionality of the latent space\")\n",
    "\n",
    "parser.add_argument(\"--pretrained\", type=bool, default=False, help=\"Use pretrained model\")\n",
    "parser.add_argument(\"--pretrained-ae\", type=bool, default=False, help=\"Use pretrained model for autoencoder\")\n",
    "\n",
    "parser.add_argument(\"--expPATH\", type=str, default=os.path.expanduser('~/workspace/pytorch-exports/models/{}'.format(experimentName)), help=\"Export Path\")\n",
    "\n",
    "opt = parser.parse_args([])\n",
    "print(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3syZZGE3ixcZ",
    "outputId": "61959d3b-2751-4dc6-983e-b8a585d49524",
    "tags": []
   },
   "outputs": [],
   "source": [
    "######################\n",
    "### Initialization ###\n",
    "######################\n",
    "\n",
    "# Create experiments DIR\n",
    "if not os.path.exists(opt.expPATH):\n",
    "    os.system('mkdir -p {0}'.format(opt.expPATH))\n",
    "\n",
    "# opt.seed = 1024 # fix seed\n",
    "opt.seed = random.randint(1, 10000)\n",
    "\n",
    "print('Random Seed: {}'.format(opt.seed))\n",
    "random.seed(opt.seed)\n",
    "torch.manual_seed(opt.seed)\n",
    "np.random.seed(opt.seed)\n",
    "cudnn.benchmark = True\n",
    "\n",
    "if torch.cuda.is_available() and not opt.cuda:\n",
    "    print(\"WARNING: You have a CUDA device BUT it is not in use...\")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if opt.cuda else \"cpu\")\n",
    "print('using \"{}\" as the tensor processor'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PYJtIeTEil-P"
   },
   "outputs": [],
   "source": [
    "#################################\n",
    "### Reading Dataset from File ###\n",
    "#################################\n",
    "\n",
    "input_data = np.load(opt.dataset_path)\n",
    "\n",
    "sample_size = input_data.shape[0]\n",
    "feature_size = input_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OP96S8Kbcs0y"
   },
   "outputs": [],
   "source": [
    "#####################\n",
    "### Dataset Model ###\n",
    "#####################\n",
    "\n",
    "class EPIDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.sample_size = dataset.shape[0]\n",
    "        self.feature_size = dataset.shape[1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IXkAxe6HS-KJ",
    "outputId": "a7d03e7e-d28a-4659-ac4e-e309ac562bb7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "### Dataset Processing ###\n",
    "##########################\n",
    "\n",
    "train_data = input_data[:int(0.8 * sample_size)]\n",
    "test_data = input_data[int(0.8 * sample_size):]\n",
    "print('total samples: {}, features: {}'.format(sample_size, feature_size))\n",
    "print('training data shape: {}, testing data shape: {}, dataset type: {}'.format(train_data.shape, test_data.shape, input_data.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CvS8xM1k8Teu"
   },
   "outputs": [],
   "source": [
    "training_dataloader = DataLoader(\n",
    "    EPIDataset(dataset=train_data),\n",
    "    batch_size=opt.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=opt.n_cpu\n",
    ")\n",
    "\n",
    "testing_dataloader = DataLoader(\n",
    "    EPIDataset(dataset=test_data),\n",
    "    batch_size=opt.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=opt.n_cpu\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ch3VtsBwn5p9"
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "### AutoEncoder Model ###\n",
    "#########################\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(feature_size, 128),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(128, feature_size),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        return self.encoder(x)\n",
    "    \n",
    "    def decode(self, x):\n",
    "        return self.decoder(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bgp1ytGXFDwS"
   },
   "outputs": [],
   "source": [
    "############################\n",
    "### Model Initialization ###\n",
    "############################\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "autoencoder = Autoencoder().cuda() if opt.cuda else Autoencoder()\n",
    "optimizer_A = torch.optim.Adam(autoencoder.parameters(), lr=opt.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jWlJt7_892vs",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#####################################\n",
    "###### AutoEncoder Training #########\n",
    "#####################################\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "if not opt.pretrained_ae:\n",
    "    for epoch in range(opt.n_epochs_ae):\n",
    "        train_loss = 0\n",
    "        autoencoder.train()\n",
    "        for batch in training_dataloader:\n",
    "            batch = batch.to(device)\n",
    "            gen_batch = autoencoder(batch)\n",
    "            loss_A = criterion(gen_batch, batch)\n",
    "            optimizer_A.zero_grad()\n",
    "            loss_A.backward()\n",
    "            optimizer_A.step()\n",
    "            train_loss += loss_A\n",
    "\n",
    "        print(\"[Epoch {:3d}/{:3d}] [Training Loss: {:10.2f}]\".format(epoch + 1, opt.n_epochs_ae, train_loss), flush=True)\n",
    "    torch.save(autoencoder.state_dict(), opt.expPATH + '/autoencoder.model')\n",
    "else:\n",
    "    autoencoder.load_state_dict(torch.load(opt.expPATH + '/autoencoder.model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s7xHg4CmL6BW",
    "outputId": "80fabc9d-cc40-4c5c-81cc-dbd8918cac05"
   },
   "outputs": [],
   "source": [
    "errors = 0\n",
    "for batch in testing_dataloader:\n",
    "    batch = batch.to(device)\n",
    "    gen_batch = autoencoder(batch)\n",
    "    diff = torch.abs(gen_batch - batch).view(-1).detach().cpu().numpy()\n",
    "    wrong_digits = diff[diff > 0.05]\n",
    "    errors += len(wrong_digits)\n",
    "print(\"total number of wrong digits: {}\".format(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I0I5dbr5cGlQ"
   },
   "outputs": [],
   "source": [
    "#############################\n",
    "### Generator Model ###\n",
    "#############################\n",
    "\n",
    "# Output should be 64 * 1\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.genDim = 128\n",
    "        self.linear1 = nn.Linear(opt.latent_dim, self.genDim)\n",
    "        self.bn1 = nn.BatchNorm1d(self.genDim, eps=0.001, momentum=0.01)\n",
    "        self.activation1 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(opt.latent_dim, self.genDim)\n",
    "        self.bn2 = nn.BatchNorm1d(self.genDim, eps=0.001, momentum=0.01)\n",
    "        self.activation2 = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Layer 1\n",
    "        residual = x\n",
    "        temp = self.activation1(self.bn1(self.linear1(x)))\n",
    "        out1 = temp + residual\n",
    "\n",
    "        # Layer 2\n",
    "        residual = out1\n",
    "        temp = self.activation2(self.bn2(self.linear2(out1)))\n",
    "        out2 = temp + residual\n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d5oIATq7r9ek"
   },
   "outputs": [],
   "source": [
    "###########################\n",
    "### Discriminator Model ###\n",
    "###########################\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        # Discriminator's parameters\n",
    "        self.disDim = 256\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(feature_size, self.disDim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.disDim, int(self.disDim / 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(self.disDim / 2), 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Feeding the model\n",
    "        output = self.model(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7inVoiMu9QS_",
    "tags": []
   },
   "outputs": [],
   "source": [
    "############################\n",
    "### Model Initialization ###\n",
    "############################\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "generator = Generator().cuda() if opt.cuda else Generator()\n",
    "discriminator = Discriminator().cuda() if opt.cuda else Discriminator()\n",
    "\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=opt.lr)\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e83EKUAC3Edo",
    "outputId": "047a722b-b29a-49d6-b015-1563020536d5"
   },
   "outputs": [],
   "source": [
    "if not opt.pretrained:\n",
    "    batches_done = 0\n",
    "\n",
    "    discriminator.train()\n",
    "    generator.train()\n",
    "\n",
    "    for epoch in range(opt.n_epochs):\n",
    "        epoch_start = time.time()\n",
    "        for _ in range(opt.n_critic):\n",
    "            for batch in training_dataloader:\n",
    "                # ---------------------\n",
    "                #  Train Discriminator\n",
    "                # ---------------------\n",
    "                batch = batch.to(device)\n",
    "                for dp in discriminator.parameters():\n",
    "                    dp.requires_grad = True\n",
    "\n",
    "                optimizer_D.zero_grad()\n",
    "                z = torch.randn(batch.shape[0], opt.latent_dim, device=device)\n",
    "                fake_batch = autoencoder.decode(generator(z))\n",
    "                loss_D = torch.mean(discriminator(batch), dim=0) - torch.mean(discriminator(fake_batch.detach()), dim=0)\n",
    "                loss_D.backward()\n",
    "\n",
    "                optimizer_D.step()\n",
    "\n",
    "                for dp in discriminator.parameters():\n",
    "                    dp.data.clamp_(-opt.clamp, opt.clamp)\n",
    "\n",
    "                if batches_done % opt.n_critic == 0:\n",
    "                    # -----------------\n",
    "                    #  Train Generator\n",
    "                    # -----------------\n",
    "                    for dp in discriminator.parameters():\n",
    "                        dp.requires_grad = False\n",
    "\n",
    "                    optimizer_G.zero_grad()\n",
    "\n",
    "                    z = torch.randn(batch.shape[0], opt.latent_dim, device=device)\n",
    "                    fake_batch = autoencoder.decode(generator(z))\n",
    "                    loss_G = torch.mean(discriminator(fake_batch), dim=0)\n",
    "                    loss_G.backward()\n",
    "\n",
    "                    optimizer_G.step()\n",
    "\n",
    "                batches_done += 1\n",
    "                if batches_done % (100 * opt.n_critic) == 0:\n",
    "                    print('[Epoch {:3d}/{:3d}] [Batch {:4d}/{:4d}] [D loss: {:.6f}] [G loss: {:.6f}]'.format(epoch + 1, opt.n_epochs, batches_done % (opt.n_critic * len(training_dataloader)), opt.n_critic * len(training_dataloader), loss_D.item(), loss_G.item()))\n",
    "\n",
    "        print('[Epoch {:3d}/{:3d}] [Time: {:.2f}] [D loss: {:.6f}] [G loss: {:.6f}]'.format(epoch + 1, opt.n_epochs, time.time() - epoch_start, loss_D.item(), loss_G.item()))\n",
    "\n",
    "    torch.save(generator.state_dict(), opt.expPATH + '/generator.model')\n",
    "    torch.save(discriminator.state_dict(), opt.expPATH + '/discriminator.model')\n",
    "else:\n",
    "    generator.load_state_dict(torch.load(opt.expPATH + '/generator.model'))\n",
    "    discriminator.load_state_dict(torch.load(opt.expPATH + '/discriminator.model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rEcQ_acg1xqu",
    "outputId": "c945727d-199b-42f5-a782-82a0afec4307"
   },
   "outputs": [],
   "source": [
    "autoencoder.eval()\n",
    "generator.eval()\n",
    "discriminator.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XuCmebS-zPp5"
   },
   "outputs": [],
   "source": [
    "num_fake_batches = 80\n",
    "fake_data = torch.zeros((0, feature_size), device='cpu')\n",
    "for _ in range(num_fake_batches):\n",
    "  z = torch.randn(opt.batch_size, opt.latent_dim, device=device)\n",
    "  generated_batch = generator(z)\n",
    "  fake_batch = autoencoder.decode(generator(z))\n",
    "  fake_data = torch.cat((fake_data, fake_batch.to('cpu')), 0)\n",
    "np.save(os.path.join(opt.expPATH, \"synthetic.npy\"), fake_data.detach().cpu().numpy(), allow_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u4Aw1fDwKdqj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "medGAN.UCI.ETD.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
